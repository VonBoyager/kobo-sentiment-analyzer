# Generated by Django 5.2.5 on 2025-09-25 03:13

import django.db.models.deletion
import uuid
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('frontend', '0003_rename_comments_to_review'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='TrainingData',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('text', models.TextField(help_text='Training text')),
                ('sentiment_label', models.CharField(choices=[('positive', 'Positive'), ('negative', 'Negative'), ('neutral', 'Neutral')], max_length=10)),
                ('section_scores', models.JSONField(help_text='Dictionary of section scores')),
                ('source', models.CharField(default='manual', help_text='Source of training data', max_length=100)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('is_verified', models.BooleanField(default=False, help_text='Whether data has been verified')),
            ],
            options={
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='MLModel',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('name', models.CharField(help_text='Model name', max_length=100)),
                ('model_type', models.CharField(choices=[('naive_bayes', 'Naive Bayes'), ('bertopic', 'BERTopic'), ('vader', 'VADER')], max_length=20)),
                ('version', models.CharField(default='1.0', max_length=50)),
                ('model_file', models.FileField(help_text='Serialized model file', upload_to='ml_models/')),
                ('model_config', models.JSONField(help_text='Model configuration parameters')),
                ('accuracy', models.FloatField(blank=True, help_text='Model accuracy', null=True)),
                ('precision', models.FloatField(blank=True, help_text='Model precision', null=True)),
                ('recall', models.FloatField(blank=True, help_text='Model recall', null=True)),
                ('f1_score', models.FloatField(blank=True, help_text='Model F1 score', null=True)),
                ('is_active', models.BooleanField(default=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('created_by', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='SectionTopicCorrelation',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('section_name', models.CharField(help_text='Questionnaire section name', max_length=100)),
                ('section_id', models.IntegerField(help_text='Questionnaire section ID')),
                ('topic_name', models.CharField(help_text='Topic name', max_length=200)),
                ('topic_id', models.IntegerField(help_text='Topic ID')),
                ('correlation_score', models.FloatField(help_text='Correlation between topic and section score')),
                ('negative_correlation', models.BooleanField(default=False, help_text='True if topic correlates with low scores')),
                ('sample_size', models.PositiveIntegerField(help_text='Number of samples used for correlation')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
            options={
                'ordering': ['-correlation_score'],
                'unique_together': {('section_id', 'topic_id')},
            },
        ),
        migrations.CreateModel(
            name='SentimentAnalysis',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('compound_score', models.FloatField(help_text='VADER compound score (-1 to 1)')),
                ('positive_score', models.FloatField(help_text='VADER positive score (0 to 1)')),
                ('negative_score', models.FloatField(help_text='VADER negative score (0 to 1)')),
                ('neutral_score', models.FloatField(help_text='VADER neutral score (0 to 1)')),
                ('sentiment_label', models.CharField(choices=[('positive', 'Positive'), ('negative', 'Negative'), ('neutral', 'Neutral')], max_length=10)),
                ('confidence', models.FloatField(help_text='Confidence score for sentiment classification')),
                ('analyzed_at', models.DateTimeField(auto_now_add=True)),
                ('text_length', models.PositiveIntegerField(help_text='Length of analyzed text')),
                ('response', models.OneToOneField(on_delete=django.db.models.deletion.CASCADE, related_name='sentiment_analysis', to='frontend.questionnaireresponse')),
            ],
            options={
                'ordering': ['-analyzed_at'],
            },
        ),
        migrations.CreateModel(
            name='UserFeedback',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('feedback_type', models.CharField(choices=[('helpful', 'Helpful'), ('not_helpful', 'Not Helpful'), ('partially_helpful', 'Partially Helpful')], max_length=20)),
                ('feedback_text', models.TextField(blank=True, help_text='Additional feedback text')),
                ('sentiment_accuracy', models.BooleanField(help_text='Was sentiment analysis accurate?', null=True)),
                ('topic_relevance', models.BooleanField(help_text='Were topics relevant?', null=True)),
                ('section_correlation', models.BooleanField(help_text='Were section correlations helpful?', null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('response', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='feedback', to='frontend.questionnaireresponse')),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='ml_feedback', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='TopicAnalysis',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('topic_id', models.IntegerField(help_text='BERTopic topic ID')),
                ('topic_name', models.CharField(help_text='Generated topic name', max_length=200)),
                ('topic_keywords', models.JSONField(help_text='Top keywords for this topic')),
                ('topic_probability', models.FloatField(help_text='Probability of this topic in the text')),
                ('analyzed_at', models.DateTimeField(auto_now_add=True)),
                ('response', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='topic_analyses', to='frontend.questionnaireresponse')),
            ],
            options={
                'ordering': ['-topic_probability'],
                'unique_together': {('response', 'topic_id')},
            },
        ),
    ]
